{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c918c499",
   "metadata": {},
   "source": [
    "# Second practical exercise: Grid World and Value iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8627d33",
   "metadata": {},
   "source": [
    "Repo: https://github.com/KRLGroup/RL_2025.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fca4cd",
   "metadata": {},
   "source": [
    "# A deterministic grid world"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2fc996",
   "metadata": {},
   "source": [
    "Finite grid with some obstacles inside. The agent can move up, left, right and down."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57edf28d",
   "metadata": {},
   "source": [
    "![](imgs/grid_world.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7541675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in c:\\users\\edoardo\\documents\\github\\rl_2025\\.venv\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\edoardo\\documents\\github\\rl_2025\\.venv\\lib\\site-packages (from gymnasium) (1.24.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\edoardo\\documents\\github\\rl_2025\\.venv\\lib\\site-packages (from gymnasium) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\edoardo\\documents\\github\\rl_2025\\.venv\\lib\\site-packages (from gymnasium) (4.15.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\edoardo\\documents\\github\\rl_2025\\.venv\\lib\\site-packages (from gymnasium) (0.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39fb2f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from gymnasium import spaces\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c0423ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# custom 2d grid world enviroment\n",
    "class GridWorld(gym.Env):\n",
    "    metadata = {'render.modes': ['console']}\n",
    "\n",
    "    \n",
    "    # actions available\n",
    "    UP = 0\n",
    "    LEFT = 1\n",
    "    DOWN = 2\n",
    "    RIGHT = 3\n",
    "\n",
    "\n",
    "    def __init__(self, width, height):\n",
    "        super(GridWorld, self).__init__()\n",
    "        self.ACTION_NAMES = [\"UP\", \"LEFT\", \"DOWN\", \"RIGHT\"]\n",
    "        self.num_actions = 4\n",
    "\n",
    "        self.size = width * height  # size of the grid world\n",
    "        self.num_states = self.size\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.num_obstacles = int((width+height)/2)\n",
    "        self.end_state = np.array([random.randrange(height) , random.randrange(width)], dtype=np.uint8) # goal state = bottom right cell\n",
    "        \n",
    "        while self.end_state[0] == 0 and self.end_state[1] == 0:\n",
    "                self.end_state = np.array([random.randrange(height) , random.randrange(width)], dtype=np.uint8)\n",
    "    \n",
    "        \n",
    "\n",
    "        # actions of agents : up, down, left and right\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        # observation : cell indices in the grid\n",
    "        self.observation_space = spaces.MultiDiscrete([self.height, self.width])\n",
    "\n",
    "        self.obstacles = np.zeros((height, width))\n",
    "\n",
    "        for i in range(self.num_obstacles):\n",
    "            obstacle = random.randrange(height) , random.randrange(width)\n",
    "            while obstacle in [(0, 0),tuple(self.end_state)]:\n",
    "                obstacle = random.randrange(height), random.randrange(width)\n",
    "            self.obstacles[obstacle] = 1\n",
    "\n",
    "        self.num_steps = 0\n",
    "        self.max_steps = height*width\n",
    "\n",
    "        self.current_state = np.zeros((2), np.uint8)#init state = [0,0]\n",
    "\n",
    "        self.directions = np.array([\n",
    "            [-1,0], #UP\n",
    "            [0,-1], #LEFT\n",
    "            [1,0], #DOWN\n",
    "            [0,1] #RIGHT\n",
    "        ])\n",
    "        \n",
    "    def step(self, action):\n",
    "        s_prime = self.transition_function(self.current_state, action)\n",
    "        reward = self.reward_function(s_prime)\n",
    "        terminated, truncated = self.termination_condition(s_prime)\n",
    "\n",
    "        self.current_state = s_prime\n",
    "        self.num_steps += 1\n",
    "\n",
    "        return self.current_state, reward, terminated, truncated, None\n",
    "    \n",
    "    \n",
    "    def transition_function(self, s, a): # TODO\n",
    "        \n",
    "        # Q1\n",
    "        # (a) -----------------------------------------\n",
    "        # s_prime = s + a\n",
    "        # if (s_prime < 0).any(): return s\n",
    "        # if s_prime[0] >= self.width: return s    \n",
    "        # if s_prime[1] >= self.height: return s \n",
    "        # if self.obstacles[s_prime[0], s_prime[1]] == 1: return s\n",
    "        \n",
    "        # (b) -----------------------------------------\n",
    "        # s_prime = s + self.directions[a]\n",
    "        # if (s_prime < 0).any(): return s_prime\n",
    "        # if s_prime[0] <= self.height: return s  \n",
    "        # if s_prime[1] <= self.width: return s \n",
    "        # if self.obstacles[s_prime[0], s_prime[1]] == 1: return s\n",
    "        \n",
    "        # (c) -----------------------------------------\n",
    "        s_prime = s + self.directions[a]\n",
    "        if (s_prime < 0).any(): return s\n",
    "        if s_prime[0] >= self.height: return s\n",
    "        if s_prime[1] >= self.width: return s\n",
    "        if self.obstacles[s_prime[0], s_prime[1]] == 1: return s\n",
    "        \n",
    "        \n",
    "        return s_prime\n",
    "\n",
    "    \n",
    "    def reward_function(self,s): # TODO\n",
    "        \n",
    "        # Q2\n",
    "        # (a) -----------------------------------------\n",
    "        # r = 0\n",
    "        # if (s != self.end_state).all():\n",
    "        #     r = 1\n",
    "\n",
    "        # (b) -----------------------------------------\n",
    "        r = 0\n",
    "        if (s == self.end_state).all():\n",
    "            r = 1\n",
    "\n",
    "        # (c) -----------------------------------------\n",
    "        # r = 1               \n",
    "        # if (s == self.end_state).all():\n",
    "        #     r = 0             \n",
    "\n",
    "        return r\n",
    "\n",
    "    def termination_condition(self, s):\n",
    "        truncated = False\n",
    "        terminated = False\n",
    "\n",
    "        # Q3\n",
    "        # (a)\n",
    "        truncated = self.num_steps >= self.max_steps\n",
    "        # (b) \n",
    "        # truncated = self.num_steps <= self.max_steps\n",
    "        # (c) \n",
    "        # truncated = self.num_steps > 5\n",
    "        #-----------------------------------------------------\n",
    "\n",
    "        # Q4\n",
    "        # (a) \n",
    "        # terminated = (s != self.end_state).any() \n",
    "        # (b) \n",
    "        # terminated = (s == self.end_state).any()\n",
    "        # (c) \n",
    "        terminated = (s == self.end_state).all()\n",
    "\n",
    "        return terminated, truncated\n",
    "    \n",
    "    def transition_probabilities(self, s, a):\n",
    "        prob_next_state = np.zeros((self.height, self.width))\n",
    "        s_prime = self.transition_function(s, a)\n",
    "\n",
    "        prob_next_state[s_prime[0], s_prime[1]] = 1.0\n",
    "\n",
    "        return prob_next_state#.flatten()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.current_state = np.zeros((2), np.uint8)\n",
    "        self.num_steps = 0\n",
    "\n",
    "        return self.current_state\n",
    "    \n",
    "    def reward_probabilities(self):\n",
    "        rewards = np.zeros((self.num_states))\n",
    "        i = 0\n",
    "        for r in range(self.height):\n",
    "            for c in range(self.width):\n",
    "                state = np.array([r,c], dtype=np.uint8)\n",
    "                rewards[i] = self.reward_function(state)\n",
    "                i+=1\n",
    "\n",
    "        return rewards\n",
    "    \n",
    "    def render(self):\n",
    "        '''\n",
    "            render the state\n",
    "        '''\n",
    "\n",
    "        row = self.current_state[0]\n",
    "        col = self.current_state[1]\n",
    "\n",
    "        for r in range(self.height):\n",
    "            for c in range(self.width):\n",
    "                if r == row and c == col:\n",
    "                    print(\"| A \", end='')\n",
    "                elif r == self.end_state[0] and c == self.end_state[1]:\n",
    "                    print(\"| G \", end='')\n",
    "                else:\n",
    "                    if self.obstacles[r,c] == 1:\n",
    "                        print('|///', end='')\n",
    "                    else:\n",
    "                        print('|___', end='')\n",
    "            print('|')\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b573a8",
   "metadata": {},
   "source": [
    "Simulate all the four actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0ed5bff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| A |///|___|\n",
      "|___|___|///|\n",
      "|///|___|___|\n",
      "|___|___|___|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "UP\n",
      "| A |///|___|\n",
      "|___|___|///|\n",
      "|///|___|___|\n",
      "|___|___|___|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "LEFT\n",
      "| A |///|___|\n",
      "|___|___|///|\n",
      "|///|___|___|\n",
      "|___|___|___|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "DOWN\n",
      "|___|///|___|\n",
      "| A |___|///|\n",
      "|///|___|___|\n",
      "|___|___|___|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "RIGHT\n",
      "|___|///|___|\n",
      "|___| A |///|\n",
      "|///|___|___|\n",
      "|___|___|___|\n",
      "|___|///| G |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = GridWorld(5,5)\n",
    "env.reset()\n",
    "env.render()\n",
    "\n",
    "action_sequence = [0,1,2,3]\n",
    "\n",
    "for a in action_sequence:\n",
    "    print(env.ACTION_NAMES[a])\n",
    "    env.step(a)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4998a26",
   "metadata": {},
   "source": [
    "Simulate a random episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b63f0500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEFT\n",
      "| A |___|___|\n",
      "|___|___|___|\n",
      "|___|///|___|\n",
      "|___|___|___|\n",
      "|///|///| G |\n",
      "\n",
      "\n",
      "RIGHT\n",
      "|___| A |___|\n",
      "|___|___|___|\n",
      "|___|///|___|\n",
      "|___|___|___|\n",
      "|///|///| G |\n",
      "\n",
      "\n",
      "UP\n",
      "|___| A |___|\n",
      "|___|___|___|\n",
      "|___|///|___|\n",
      "|___|___|___|\n",
      "|///|///| G |\n",
      "\n",
      "\n",
      "DOWN\n",
      "|___|___|___|\n",
      "|___| A |___|\n",
      "|___|///|___|\n",
      "|___|___|___|\n",
      "|///|///| G |\n",
      "\n",
      "\n",
      "DOWN\n",
      "|___|___|___|\n",
      "|___| A |___|\n",
      "|___|///|___|\n",
      "|___|___|___|\n",
      "|///|///| G |\n",
      "\n",
      "\n",
      "RIGHT\n",
      "|___|___|___|\n",
      "|___|___| A |\n",
      "|___|///|___|\n",
      "|___|___|___|\n",
      "|///|///| G |\n",
      "\n",
      "\n",
      "LEFT\n",
      "|___|___|___|\n",
      "|___| A |___|\n",
      "|___|///|___|\n",
      "|___|___|___|\n",
      "|///|///| G |\n",
      "\n",
      "\n",
      "LEFT\n",
      "|___|___|___|\n",
      "| A |___|___|\n",
      "|___|///|___|\n",
      "|___|___|___|\n",
      "|///|///| G |\n",
      "\n",
      "\n",
      "LEFT\n",
      "|___|___|___|\n",
      "| A |___|___|\n",
      "|___|///|___|\n",
      "|___|___|___|\n",
      "|///|///| G |\n",
      "\n",
      "\n",
      "RIGHT\n",
      "|___|___|___|\n",
      "|___| A |___|\n",
      "|___|///|___|\n",
      "|___|___|___|\n",
      "|///|///| G |\n",
      "\n",
      "\n",
      "DOWN\n",
      "|___|___|___|\n",
      "|___| A |___|\n",
      "|___|///|___|\n",
      "|___|___|___|\n",
      "|///|///| G |\n",
      "\n",
      "\n",
      "LEFT\n",
      "|___|___|___|\n",
      "| A |___|___|\n",
      "|___|///|___|\n",
      "|___|___|___|\n",
      "|///|///| G |\n",
      "\n",
      "\n",
      "RIGHT\n",
      "|___|___|___|\n",
      "|___| A |___|\n",
      "|___|///|___|\n",
      "|___|___|___|\n",
      "|///|///| G |\n",
      "\n",
      "\n",
      "RIGHT\n",
      "|___|___|___|\n",
      "|___|___| A |\n",
      "|___|///|___|\n",
      "|___|___|___|\n",
      "|///|///| G |\n",
      "\n",
      "\n",
      "LEFT\n",
      "|___|___|___|\n",
      "|___| A |___|\n",
      "|___|///|___|\n",
      "|___|___|___|\n",
      "|///|///| G |\n",
      "\n",
      "\n",
      "LEFT\n",
      "|___|___|___|\n",
      "| A |___|___|\n",
      "|___|///|___|\n",
      "|___|___|___|\n",
      "|///|///| G |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "env.reset()\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    print(env.ACTION_NAMES[action])\n",
    "    state, reward, terminated, truncated, _ = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    env.render()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f55b2b3",
   "metadata": {},
   "source": [
    "## A non deterministic grid world"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a7d325",
   "metadata": {},
   "source": [
    "The agent goes with probability p to the right cell, with probability 1 - p in a different cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbfb3164",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonDeterministicGridWorld(GridWorld):\n",
    "    def __init__(self, width, height, p=0.8):\n",
    "        super(NonDeterministicGridWorld, self).__init__(width, height)\n",
    "        self.probability_right_action = p\n",
    "\n",
    "    def transition_function(self, s, a):\n",
    "        s_prime = s + self.directions[a, :]\n",
    "\n",
    "        #with probability 1 - p diagonal movement\n",
    "        if random.random() <= 1 - self.probability_right_action:\n",
    "            if random.random() < 0.5:\n",
    "                s_prime = s_prime + self.directions[(a+1)%self.num_actions, :]\n",
    "            else:\n",
    "                s_prime = s_prime + self.directions[(a-1)%self.num_actions, :]\n",
    "\n",
    "\n",
    "        if s_prime[0] < self.height and s_prime[1] < self.width and (s_prime >= 0).all():\n",
    "            if self.obstacles[s_prime[0], s_prime[1]] == 0 :\n",
    "                return s_prime\n",
    "\n",
    "        return s\n",
    "\n",
    "    def transition_probabilities(self, s, a):\n",
    "        cells = []\n",
    "        probs = []\n",
    "        prob_next_state = np.zeros((self.height, self.width))\n",
    "        s_prime_right =  s + self.directions[a, :]\n",
    "        if s_prime_right[0] < self.height and s_prime_right[1] < self.width and (s_prime_right >= 0).all():\n",
    "            if self.obstacles[s_prime_right[0], s_prime_right[1]] == 0 :\n",
    "                prob_next_state[s_prime_right[0], s_prime_right[1]] = self.probability_right_action\n",
    "                cells.append(s_prime_right)\n",
    "                probs.append(self.probability_right_action)\n",
    "\n",
    "        s_prime = s_prime_right + self.directions[(a + 1) % self.num_actions, :]\n",
    "        if s_prime[0] < self.height and s_prime[1] < self.width and (s_prime >= 0).all():\n",
    "            if self.obstacles[s_prime[0], s_prime[1]] == 0 :\n",
    "                prob_next_state[s_prime[0], s_prime[1]] = (1 - self.probability_right_action) / 2\n",
    "                cells.append(s_prime.copy())\n",
    "                probs.append((1 - self.probability_right_action) / 2)\n",
    "\n",
    "        s_prime = s_prime_right + self.directions[(a - 1) % self.num_actions, :]\n",
    "        if s_prime[0] < self.height and s_prime[1] < self.width and (s_prime >= 0).all():\n",
    "            if self.obstacles[s_prime[0], s_prime[1]] == 0 :\n",
    "                prob_next_state[s_prime[0], s_prime[1]] = (1 - self.probability_right_action) / 2\n",
    "                cells.append(s_prime.copy())\n",
    "                probs.append((1 - self.probability_right_action) / 2)\n",
    "\n",
    "        #normalization\n",
    "        sump = sum(probs)\n",
    "        #for cell in cells:\n",
    "        #    prob_next_state[cell[0], cell[1]] /= sump\n",
    "        prob_next_state[s[0], s[1]] = 1 - sump\n",
    "        return prob_next_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dccd6e7",
   "metadata": {},
   "source": [
    "Simulate a random episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ad16ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| A |___|___|\n",
      "|___|///|///|\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "[[0.9 0.  0. ]\n",
      " [0.  0.1 0. ]\n",
      " [0.  0.  0. ]\n",
      " [0.  0.  0. ]\n",
      " [0.  0.  0. ]]\n",
      "\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "env = NonDeterministicGridWorld(3,5)\n",
    "state = env.reset()\n",
    "env.render()\n",
    "#next state if we start from state 0,0 and we do action down\n",
    "next_state_prob = env.transition_probabilities(state, 2)\n",
    "print(next_state_prob)\n",
    "print()\n",
    "print(env.reward_probabilities())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5823a401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIGHT\n",
      "| A |___|___|\n",
      "|___|///|///|\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "LEFT\n",
      "| A |___|___|\n",
      "|___|///|///|\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "RIGHT\n",
      "|___| A |___|\n",
      "|___|///|///|\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "UP\n",
      "|___| A |___|\n",
      "|___|///|///|\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "LEFT\n",
      "| A |___|___|\n",
      "|___|///|///|\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "RIGHT\n",
      "|___| A |___|\n",
      "|___|///|///|\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "UP\n",
      "|___| A |___|\n",
      "|___|///|///|\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "RIGHT\n",
      "|___|___| A |\n",
      "|___|///|///|\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "LEFT\n",
      "|___| A |___|\n",
      "|___|///|///|\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "DOWN\n",
      "|___| A |___|\n",
      "|___|///|///|\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "UP\n",
      "|___| A |___|\n",
      "|___|///|///|\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "DOWN\n",
      "|___|___|___|\n",
      "| A |///|///|\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "UP\n",
      "|___|___|___|\n",
      "| A |///|///|\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "DOWN\n",
      "|___|___|___|\n",
      "|___|///|///|\n",
      "| A |___|___|\n",
      "|___|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "UP\n",
      "|___|___|___|\n",
      "| A |///|///|\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n",
      "RIGHT\n",
      "|___|___|___|\n",
      "| A |///|///|\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|___|///| G |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    print(env.ACTION_NAMES[action])\n",
    "    state, reward, terminated, truncated, _ = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33758b3e",
   "metadata": {},
   "source": [
    "VALUE ITERATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17837d79",
   "metadata": {},
   "source": [
    "![](imgs/value_iteration_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f7efca",
   "metadata": {},
   "source": [
    "![](imgs/value_iteration_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83617227",
   "metadata": {},
   "source": [
    "![](imgs/value_iteration_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c379abfa",
   "metadata": {},
   "source": [
    "![](imgs/value_iteration_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba5b9af",
   "metadata": {},
   "source": [
    "![](imgs/value_iteration_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b5bc10",
   "metadata": {},
   "source": [
    "![](imgs/value_iteration_6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10fa025",
   "metadata": {},
   "source": [
    "![](imgs/value_iteration.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b096193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(env, gamma=0.99, iters=100):\n",
    "    #initialize values\n",
    "    values = np.zeros((env.num_states))\n",
    "    best_actions = np.zeros((env.num_states), dtype=int)\n",
    "    STATES = np.zeros((env.num_states, 2), dtype=np.uint8)\n",
    "    REWARDS = env.reward_probabilities()\n",
    "    print(REWARDS)\n",
    "    i = 0\n",
    "    for r in range(env.height):\n",
    "        for c in range(env.width):\n",
    "            state = np.array([r, c], dtype=np.uint8)\n",
    "            STATES[i] = state\n",
    "            i += 1\n",
    "    \n",
    "    for i in range(iters):\n",
    "        v_old = values.copy()\n",
    "        for s in range(env.num_states):\n",
    "            state = STATES[s]\n",
    "\n",
    "            if (state == env.end_state).all() or i >= env.max_steps or env.obstacles[state[0],state[1]]:\n",
    "                continue # if we reach the termination condition, we cannot perform any action\n",
    "\n",
    "\n",
    "            max_va = -np.inf\n",
    "            best_a = 0\n",
    "            for a in range(env.num_actions):\n",
    "                next_state_prob = env.transition_probabilities(state, a).flatten()\n",
    "\n",
    "                #Q5\n",
    "                # (a)\n",
    "                # va = (next_state_prob*(REWARDS + gamma*values)).sum()\n",
    "                # (b) \n",
    "                # va = (REWARDS + gamma*v_old).sum()\n",
    "                # (c) \n",
    "                va = (next_state_prob*(REWARDS + gamma*v_old)).sum()\n",
    "                \n",
    "                #Q6\n",
    "                # (a) \n",
    "                if va > max_va:\n",
    "                    max_va = va\n",
    "                    best_a = a\n",
    "                # (b) \n",
    "                # if va < max_va:\n",
    "                    # max_va = a\n",
    "                    # best_a = va\n",
    "                # (c) \n",
    "                # if va > values:\n",
    "                    # max_va = va\n",
    "                    # best_a = a\n",
    "\n",
    "            values[s] = max_va\n",
    "            best_actions[s] = best_a\n",
    "\n",
    "    return values.reshape((env.height, env.width)), best_actions.reshape((env.height, env.width))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e42916",
   "metadata": {},
   "source": [
    "estimate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3420f773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[[0.5246256  0.55784861 0.51580227]\n",
      " [0.5669092  0.60593366 0.        ]\n",
      " [0.         0.65060925 0.60593366]\n",
      " [0.97550206 0.         0.        ]\n",
      " [0.9850685  0.99750623 0.        ]]\n",
      "[[2 2 1]\n",
      " [3 2 0]\n",
      " [0 2 1]\n",
      " [2 0 0]\n",
      " [3 3 0]]\n",
      "| A |___|___|\n",
      "|___|___|///|\n",
      "|///|___|___|\n",
      "|___|///|///|\n",
      "|___|___| G |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = NonDeterministicGridWorld(10,10)\n",
    "values, best_actions = value_iteration(env, iters=5000)\n",
    "\n",
    "print(values)\n",
    "print(best_actions)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77687aaf",
   "metadata": {},
   "source": [
    "simulate optimal policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c2536107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: DOWN\n",
      "|___|___|___|\n",
      "| A |___|///|\n",
      "|///|___|___|\n",
      "|___|///|///|\n",
      "|___|___| G |\n",
      "\n",
      "\n",
      "Action: RIGHT\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|///| A |___|\n",
      "|___|///|///|\n",
      "|___|___| G |\n",
      "\n",
      "\n",
      "Action: DOWN\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|///| A |___|\n",
      "|___|///|///|\n",
      "|___|___| G |\n",
      "\n",
      "\n",
      "Action: DOWN\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|///| A |___|\n",
      "|___|///|///|\n",
      "|___|___| G |\n",
      "\n",
      "\n",
      "Action: DOWN\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|///| A |___|\n",
      "|___|///|///|\n",
      "|___|___| G |\n",
      "\n",
      "\n",
      "Action: DOWN\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|///| A |___|\n",
      "|___|///|///|\n",
      "|___|___| G |\n",
      "\n",
      "\n",
      "Action: DOWN\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|///| A |___|\n",
      "|___|///|///|\n",
      "|___|___| G |\n",
      "\n",
      "\n",
      "Action: DOWN\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|///| A |___|\n",
      "|___|///|///|\n",
      "|___|___| G |\n",
      "\n",
      "\n",
      "Action: DOWN\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|///| A |___|\n",
      "|___|///|///|\n",
      "|___|___| G |\n",
      "\n",
      "\n",
      "Action: DOWN\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|///| A |___|\n",
      "|___|///|///|\n",
      "|___|___| G |\n",
      "\n",
      "\n",
      "Action: DOWN\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|///| A |___|\n",
      "|___|///|///|\n",
      "|___|___| G |\n",
      "\n",
      "\n",
      "Action: DOWN\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|///| A |___|\n",
      "|___|///|///|\n",
      "|___|___| G |\n",
      "\n",
      "\n",
      "Action: DOWN\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|///|___|___|\n",
      "| A |///|///|\n",
      "|___|___| G |\n",
      "\n",
      "\n",
      "Action: DOWN\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|///|___|___|\n",
      "|___|///|///|\n",
      "| A |___| G |\n",
      "\n",
      "\n",
      "Action: RIGHT\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|///|___|___|\n",
      "|___|///|///|\n",
      "|___| A | G |\n",
      "\n",
      "\n",
      "Action: RIGHT\n",
      "|___|___|___|\n",
      "|___|___|///|\n",
      "|///|___|___|\n",
      "|___|///|///|\n",
      "|___|___| A |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "state = env.reset()\n",
    "while not done:\n",
    "    action = best_actions[state[0],state[1]]\n",
    "    print(\"Action:\",env.ACTION_NAMES[action])\n",
    "    state, reward, terminated, truncated, _ = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    env.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50158163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Griglia creata: 5x3 con 4 ostacoli\n",
      "| A |///|___|\n",
      "|///|___|___|\n",
      "|___|___|///|\n",
      "|___|///|___|\n",
      "|___|___| G |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Crea l'environment\n",
    "env = NonDeterministicGridWorld(3, 5)\n",
    "\n",
    "def create_grid_from_env(env, image_paths, output_path):\n",
    "    \"\"\"\n",
    "    Crea un'immagine della griglia usando le informazioni dell'environment\n",
    "    \"\"\"\n",
    "    img_dict = {\n",
    "        'cell': Image.open(image_paths[0]),\n",
    "        'start': Image.open(image_paths[1]),\n",
    "        'obstacle': Image.open(image_paths[2]),\n",
    "        'end': Image.open(image_paths[3])\n",
    "    }\n",
    "    \n",
    "    # Crea l'immagine della griglia\n",
    "    grid_img = Image.new('RGB', (env.width * 100, env.height * 100), color='white')\n",
    "    \n",
    "    # Itera su tutte le celle\n",
    "    for r in range(env.height):\n",
    "        for c in range(env.width):\n",
    "            # Determina il tipo di cella\n",
    "            if r == 0 and c == 0:\n",
    "                cell_type = 'start'\n",
    "            elif r == env.end_state[0] and c == env.end_state[1]:\n",
    "                cell_type = 'end'\n",
    "            elif env.obstacles[r, c] == 1:\n",
    "                cell_type = 'obstacle'\n",
    "            else:\n",
    "                cell_type = 'cell'\n",
    "            \n",
    "            # Incolla l'immagine nella posizione corretta (colonna * 100, riga * 100)\n",
    "            grid_img.paste(img_dict[cell_type], (c * 100, r * 100))\n",
    "    \n",
    "    grid_img.save(output_path)\n",
    "    return grid_img\n",
    "\n",
    "# Crea l'immagine della griglia\n",
    "image_paths = ['cell.jpg', 'start.jpg', 'obstacle.jpg', 'end.jpg']\n",
    "grid_img = create_grid_from_env(env, image_paths, 'grid_from_env.png')\n",
    "print(f\"Griglia creata: {env.height}x{env.width} con {int(env.obstacles.sum())} ostacoli\")\n",
    "env.render()\n",
    "\n",
    "\n",
    "\n",
    "done = False\n",
    "state = env.reset()\n",
    "while not done:\n",
    "    action = best_actions[state[0],state[1]]\n",
    "    print(\"Action:\",env.ACTION_NAMES[action])\n",
    "    state, reward, terminated, truncated, _ = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03cffd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIF creata: animazione_griglia.gif con 15 frames\n"
     ]
    }
   ],
   "source": [
    "def create_red_circle_image(path='pawn_circle.png'):\n",
    "    \"\"\"Crea un'immagine 100x100 con un cerchio rosso 80x80 su sfondo trasparente\"\"\"\n",
    "    img = Image.new('RGBA', (100, 100), (0, 0, 0, 0))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.ellipse((10, 10, 90, 90), fill=(255, 0, 0, 255))\n",
    "    img.save(path)\n",
    "    return img\n",
    "\n",
    "def animate_pawn_on_grid(env, image_paths, pawn_img, output_gif):\n",
    "    \"\"\"\n",
    "    Crea una GIF animata che sposta il cerchio rosso su ogni cella della griglia\n",
    "    \"\"\"\n",
    "    img_dict = {\n",
    "        'cell': Image.open(image_paths[0]),\n",
    "        'start': Image.open(image_paths[1]),\n",
    "        'obstacle': Image.open(image_paths[2]),\n",
    "        'end': Image.open(image_paths[3])\n",
    "    }\n",
    "    \n",
    "    frames = []\n",
    "    \n",
    "    # Itera su tutte le celle della griglia\n",
    "    for r in range(env.height):\n",
    "        for c in range(env.width):\n",
    "            # Crea un frame per questa posizione\n",
    "            frame = Image.new('RGB', (env.width * 100, env.height * 100), color='white')\n",
    "            \n",
    "            # Disegna tutte le celle della griglia\n",
    "            for row in range(env.height):\n",
    "                for col in range(env.width):\n",
    "                    # Determina il tipo di cella\n",
    "                    if row == 0 and col == 0:\n",
    "                        cell_type = 'start'\n",
    "                    elif row == env.end_state[0] and col == env.end_state[1]:\n",
    "                        cell_type = 'end'\n",
    "                    elif env.obstacles[row, col] == 1:\n",
    "                        cell_type = 'obstacle'\n",
    "                    else:\n",
    "                        cell_type = 'cell'\n",
    "                    \n",
    "                    # Incolla l'immagine della cella\n",
    "                    frame.paste(img_dict[cell_type], (col * 100, row * 100))\n",
    "            \n",
    "            # Sovrapponi il cerchio rosso sulla posizione corrente (c * 100, r * 100)\n",
    "            frame.paste(pawn_img, (c * 100, r * 100), pawn_img)\n",
    "            frames.append(frame)\n",
    "    \n",
    "    # Salva la GIF\n",
    "    frames[0].save(output_gif, save_all=True, append_images=frames[1:], duration=200, loop=0)\n",
    "    print(f\"GIF creata: {output_gif} con {len(frames)} frames\")\n",
    "\n",
    "# Crea il cerchio rosso\n",
    "pawn_img = create_red_circle_image()\n",
    "\n",
    "# Crea la GIF animata\n",
    "image_paths = ['cell.jpg', 'start.jpg', 'obstacle.jpg', 'end.jpg']\n",
    "animate_pawn_on_grid(env, image_paths, pawn_img, 'animazione_griglia.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7eae45e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: State [0,0], Action: RIGHT\n",
      "Step 1: State [0,0], Action: RIGHT\n",
      "Step 2: State [0,0], Action: RIGHT\n",
      "Step 3: State [1,1], Action: DOWN\n",
      "Step 4: State [2,1], Action: DOWN\n",
      "Step 5: State [3,1], Action: RIGHT\n",
      "Step 6: State [3,2], Action: DOWN\n",
      "Step 7: State [3,2], Action: DOWN\n",
      "Step 8: State [4,3], Action: DOWN\n",
      "Step 9: State [5,3], Action: RIGHT\n",
      "Step 10: State [5,4], Action: RIGHT\n",
      "Step 11: State [5,5], Action: RIGHT\n",
      "Step 12: State [5,6], Action: RIGHT\n",
      "Step 13: State [5,7], Action: DOWN\n",
      "Step 14: State [6,7], Action: RIGHT\n",
      "Step 15: State [6,8], Action: DOWN\n",
      "Step 16: State [7,8], Action: RIGHT\n",
      "Step 17: State [7,9], Action: DOWN\n",
      "Step 18: State [8,9], Action: RIGHT\n",
      "Step 19: State [8,10], Action: DOWN\n",
      "Step 20: State [9,10], Action: RIGHT\n",
      "Step 21: State [10,11], Action: RIGHT\n",
      "Step 22: State [9,12], Action: DOWN\n",
      "Step 23: State [10,12], Action: DOWN\n",
      "Step 24: State [11,12], Action: DOWN\n",
      "Step 25: State [12,12], Action: DOWN\n",
      "Step 26: State [13,11], Action: RIGHT\n",
      "Step 27: State [13,12], Action: RIGHT\n",
      "Step 28: State [13,13], Action: DOWN\n",
      "Step 29: State [14,13], Action: RIGHT\n",
      "\n",
      "GIF creata: optimal_policy.gif con 31 frames (percorso ottimale)\n",
      "\n",
      "GIF creata: optimal_policy.gif con 31 frames (percorso ottimale)\n"
     ]
    }
   ],
   "source": [
    "def animate_optimal_policy(env, best_actions, image_paths, pawn_img, output_gif):\n",
    "    \"\"\"\n",
    "    Crea una GIF animata che mostra il cerchio rosso seguire la policy ottimale\n",
    "    \"\"\"\n",
    "    img_dict = {\n",
    "        'cell': Image.open(image_paths[0]),\n",
    "        'start': Image.open(image_paths[1]),\n",
    "        'obstacle': Image.open(image_paths[2]),\n",
    "        'end': Image.open(image_paths[3])\n",
    "    }\n",
    "    \n",
    "    frames = []\n",
    "    \n",
    "    # Simula l'episodio seguendo la policy ottimale\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    step_count = 0\n",
    "    max_steps = env.height * env.width  # Limite per evitare loop infiniti\n",
    "    \n",
    "    while not done and step_count < max_steps:\n",
    "        # Crea un frame per questa posizione\n",
    "        frame = Image.new('RGB', (env.width * 100, env.height * 100), color='white')\n",
    "        \n",
    "        # Disegna tutte le celle della griglia\n",
    "        for row in range(env.height):\n",
    "            for col in range(env.width):\n",
    "                # Determina il tipo di cella\n",
    "                if row == 0 and col == 0:\n",
    "                    cell_type = 'start'\n",
    "                elif row == env.end_state[0] and col == env.end_state[1]:\n",
    "                    cell_type = 'end'\n",
    "                elif env.obstacles[row, col] == 1:\n",
    "                    cell_type = 'obstacle'\n",
    "                else:\n",
    "                    cell_type = 'cell'\n",
    "                \n",
    "                # Incolla l'immagine della cella\n",
    "                frame.paste(img_dict[cell_type], (col * 100, row * 100))\n",
    "        \n",
    "        # Sovrapponi il cerchio rosso sulla posizione corrente dello stato\n",
    "        frame.paste(pawn_img, (state[1] * 100, state[0] * 100), pawn_img)\n",
    "        frames.append(frame)\n",
    "        \n",
    "        # Prendi la migliore azione per questo stato\n",
    "        action = best_actions[state[0], state[1]]\n",
    "        print(f\"Step {step_count}: State [{state[0]},{state[1]}], Action: {env.ACTION_NAMES[action]}\")\n",
    "        \n",
    "        # Esegui l'azione\n",
    "        state, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        step_count += 1\n",
    "    \n",
    "    # Aggiungi un ultimo frame con lo stato finale\n",
    "    frame = Image.new('RGB', (env.width * 100, env.height * 100), color='white')\n",
    "    for row in range(env.height):\n",
    "        for col in range(env.width):\n",
    "            if row == 0 and col == 0:\n",
    "                cell_type = 'start'\n",
    "            elif row == env.end_state[0] and col == env.end_state[1]:\n",
    "                cell_type = 'end'\n",
    "            elif env.obstacles[row, col] == 1:\n",
    "                cell_type = 'obstacle'\n",
    "            else:\n",
    "                cell_type = 'cell'\n",
    "            frame.paste(img_dict[cell_type], (col * 100, row * 100))\n",
    "    frame.paste(pawn_img, (state[1] * 100, state[0] * 100), pawn_img)\n",
    "    frames.append(frame)\n",
    "    \n",
    "    # Salva la GIF\n",
    "    if len(frames) > 0:\n",
    "        frames[0].save(output_gif, save_all=True, append_images=frames[1:], duration=300, loop=0)\n",
    "        print(f\"\\nGIF creata: {output_gif} con {len(frames)} frames (percorso ottimale)\")\n",
    "    else:\n",
    "        print(\"Nessun frame generato!\")\n",
    "\n",
    "\n",
    "env = NonDeterministicGridWorld(15,15)\n",
    "# Crea il cerchio rosso\n",
    "pawn_img = create_red_circle_image()\n",
    "\n",
    "# Crea la GIF animata seguendo la policy ottimale\n",
    "image_paths = ['cell.jpg', 'start.jpg', 'obstacle.jpg', 'end.jpg']\n",
    "animate_optimal_policy(env, best_actions, image_paths, pawn_img, 'optimal_policy.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bb68ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "DependencyNotInstalled",
     "evalue": "Box2D is not installed, you can install it by run `pip install swig` followed by `pip install \"gymnasium[box2d]\"`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Edoardo\\Documents\\GitHub\\RL_2025\\.venv\\lib\\site-packages\\gymnasium\\envs\\box2d\\bipedal_walker.py:15\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mBox2D\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mBox2D\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mb2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     17\u001b[0m         circleShape,\n\u001b[0;32m     18\u001b[0m         contactListener,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m         revoluteJointDef,\n\u001b[0;32m     23\u001b[0m     )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Box2D'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDependencyNotInstalled\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgym\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Initialise the environment\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mgym\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLunarLander-v3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrender_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhuman\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Reset the environment to generate the first observation\u001b[39;00m\n\u001b[0;32m      7\u001b[0m observation, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Edoardo\\Documents\\GitHub\\RL_2025\\.venv\\lib\\site-packages\\gymnasium\\envs\\registration.py:696\u001b[0m, in \u001b[0;36mmake\u001b[1;34m(id, max_episode_steps, disable_env_checker, **kwargs)\u001b[0m\n\u001b[0;32m    693\u001b[0m     env_creator \u001b[38;5;241m=\u001b[39m env_spec\u001b[38;5;241m.\u001b[39mentry_point\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    695\u001b[0m     \u001b[38;5;66;03m# Assume it's a string\u001b[39;00m\n\u001b[1;32m--> 696\u001b[0m     env_creator \u001b[38;5;241m=\u001b[39m \u001b[43mload_env_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentry_point\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;66;03m# Determine if to use the rendering\u001b[39;00m\n\u001b[0;32m    699\u001b[0m render_modes: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Edoardo\\Documents\\GitHub\\RL_2025\\.venv\\lib\\site-packages\\gymnasium\\envs\\registration.py:544\u001b[0m, in \u001b[0;36mload_env_creator\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads an environment with name of style ``\"(import path):(environment name)\"`` and returns the environment creation function, normally the environment class type.\u001b[39;00m\n\u001b[0;32m    536\u001b[0m \n\u001b[0;32m    537\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;124;03m    The environment constructor for the given environment name.\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    543\u001b[0m mod_name, attr_name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 544\u001b[0m mod \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    545\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(mod, attr_name)\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:992\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Edoardo\\Documents\\GitHub\\RL_2025\\.venv\\lib\\site-packages\\gymnasium\\envs\\box2d\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbox2d\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbipedal_walker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BipedalWalker, BipedalWalkerHardcore\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbox2d\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcar_racing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CarRacing\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbox2d\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlunar_lander\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LunarLander, LunarLanderContinuous\n",
      "File \u001b[1;32mc:\\Users\\Edoardo\\Documents\\GitHub\\RL_2025\\.venv\\lib\\site-packages\\gymnasium\\envs\\box2d\\bipedal_walker.py:25\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mBox2D\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mb2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     17\u001b[0m         circleShape,\n\u001b[0;32m     18\u001b[0m         contactListener,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m         revoluteJointDef,\n\u001b[0;32m     23\u001b[0m     )\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 25\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DependencyNotInstalled(\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBox2D is not installed, you can install it by run `pip install swig` followed by `pip install \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgymnasium[box2d]\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     27\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpygame\u001b[39;00m\n",
      "\u001b[1;31mDependencyNotInstalled\u001b[0m: Box2D is not installed, you can install it by run `pip install swig` followed by `pip install \"gymnasium[box2d]\"`"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import swig\n",
    "\n",
    "\n",
    "# Initialise the environment\n",
    "env = gym.make(\"LunarLander-v3\", render_mode=\"human\")\n",
    "\n",
    "# Reset the environment to generate the first observation\n",
    "observation, info = env.reset(seed=42)\n",
    "for _ in range(1000):\n",
    "    # this is where you would insert your policy\n",
    "    action = env.action_space.sample()\n",
    "\n",
    "    # step (transition) through the environment with the action\n",
    "    # receiving the next observation, reward and if the episode has terminated or truncated\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    # If the episode has ended then we can reset to start a new episode\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
